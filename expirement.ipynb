{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faf5d4d-ddab-4d99-9f0c-eb6ea6054fe5",
   "metadata": {},
   "source": [
    "# Get the data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2ae429-5f00-4f92-8dcc-444fb3264283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b82976-d9ef-4555-b39c-8985841256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the data from the url to the data_path\n",
    "def get_data(url, data_path):\n",
    "    if data_path.is_file():\n",
    "        print(f\"The file {data_path} already exists.\")\n",
    "    \n",
    "    else:\n",
    "        Path(\"data\").mkdir(parents = True, exist_ok = True)\n",
    "        with open(data_path, \"wb\") as f:\n",
    "            request = requests.get(url)\n",
    "            f.write(request.content)\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57473904-ea01-4421-be83-55fa7f6b0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file data/input.txt already exists.\n",
      "The lenght of dataset in character is 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "data_path = Path(\"data/input.txt\")\n",
    "text = get_data(url, data_path)\n",
    "print(f\"The lenght of dataset in character is {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae831b0-46d5-4b8a-bab3-3a04919557a8",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f4e167-0f79-4bb3-89e7-6e183251665a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2480a7b-0669-4416-9a1b-c19d815bc812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab size is: 65 characters,\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# List all the unique characters in the text\n",
    "characters = sorted(list(set(text)))\n",
    "vocab_size = len(characters)\n",
    "print(f\"The vocab size is: {vocab_size} characters,\")\n",
    "print(\"\".join(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2193863-b379-48ff-a11a-0340fcb710a1",
   "metadata": {},
   "source": [
    "# Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3acafec-5e1d-4e4f-8ba4-b227ae3c59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42]\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# create a mapping of character to integers(index) for encoder and decoder\n",
    "\n",
    "encoder_mapping = {ch:i for i,ch in enumerate(characters)}\n",
    "decoder_mapping = {i:ch for i,ch in enumerate(characters)}\n",
    "\n",
    "encode = lambda s: [encoder_mapping[c] for c in s] # takes a string and outputs list of integers according to our mapping\n",
    "decode = lambda l: \"\".join([decoder_mapping[i] for i in l]) # takes a list of integers and maps it to string according to its mapping\n",
    "\n",
    "print(encode(\"Hello World\"))\n",
    "print(decode(encode(\"Hello World\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3fc4cfa-23b8-490d-a472-552d617d2bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape : torch.Size([1115394]), Data Type: <built-in method type of Tensor object at 0x107243e30>\n",
      "\n",
      " The first 100 tokens: \n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# creating the tokens for the whole dataset\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(f\"Data shape : {data.shape}, Data Type: {data.type}\")\n",
    "print(f\"\\n The first 100 tokens: \\n{data[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c2477-6f5c-401b-9cf0-263ee37753d2",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f62214-3ce6-4dfa-9a93-8887177ce18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't shuffle because here the sequence matters\n",
    "n = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:n] # 90% training data\n",
    "val_data = data[n:] # 10% validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bfd35c-e1ba-456c-8891-481732e02b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1] # +1 because with block_size of 8 the 9th token is the target for block_size of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120f924d-cb80-4bf4-88b3-30ff32807486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target is 47\n",
      "When input is tensor([18, 47]) the target is 56\n",
      "When input is tensor([18, 47, 56]) the target is 57\n",
      "When input is tensor([18, 47, 56, 57]) the target is 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for token in range(block_size):\n",
    "    context = x[:token+1]\n",
    "    target = y[token]\n",
    "    print(f\"When input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a16cc0-cd27-4b6c-8497-c8c8fe7f6493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56, 57, 58,  1, 15, 47]),\n",
       " tensor([47, 56, 57, 58,  1, 15, 47, 58]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x , y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6ea81-529d-4c51-865f-d07385a4f088",
   "metadata": {},
   "source": [
    "# Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e682d9c-ec38-4f7d-871d-d6d25bd02dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    idx = torch.randint(low = 0, high = len(data)- block_size, size=(batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in idx])\n",
    "    y = torch.stack([data[i+1 : i + block_size + 1] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "x_batch, y_batch = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(x_batch.shape)\n",
    "print(x_batch)\n",
    "print(\"targets:\")\n",
    "print(y_batch.shape)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed493488-a306-4680-bc81-4141b113115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(65, 65)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table = torch.nn.Embedding(65,65)\n",
    "embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb78f047-3719-4c22-8d2f-21c16e21f050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1, 1, 1, 1, 65])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_table(torch.tensor([[[[[[[1]]]]]]]))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804e0a67-8046-496d-8118-2208c973f7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is [24] the target is: 43\n",
      "When input is [24, 43] the target is: 58\n",
      "When input is [24, 43, 58] the target is: 5\n",
      "When input is [24, 43, 58, 5] the target is: 57\n",
      "When input is [24, 43, 58, 5, 57] the target is: 1\n",
      "When input is [24, 43, 58, 5, 57, 1] the target is: 46\n",
      "When input is [24, 43, 58, 5, 57, 1, 46] the target is: 43\n",
      "When input is [24, 43, 58, 5, 57, 1, 46, 43] the target is: 39\n",
      "When input is [44] the target is: 53\n",
      "When input is [44, 53] the target is: 56\n",
      "When input is [44, 53, 56] the target is: 1\n",
      "When input is [44, 53, 56, 1] the target is: 58\n",
      "When input is [44, 53, 56, 1, 58] the target is: 46\n",
      "When input is [44, 53, 56, 1, 58, 46] the target is: 39\n",
      "When input is [44, 53, 56, 1, 58, 46, 39] the target is: 58\n",
      "When input is [44, 53, 56, 1, 58, 46, 39, 58] the target is: 1\n",
      "When input is [52] the target is: 58\n",
      "When input is [52, 58] the target is: 1\n",
      "When input is [52, 58, 1] the target is: 58\n",
      "When input is [52, 58, 1, 58] the target is: 46\n",
      "When input is [52, 58, 1, 58, 46] the target is: 39\n",
      "When input is [52, 58, 1, 58, 46, 39] the target is: 58\n",
      "When input is [52, 58, 1, 58, 46, 39, 58] the target is: 1\n",
      "When input is [52, 58, 1, 58, 46, 39, 58, 1] the target is: 46\n",
      "When input is [25] the target is: 17\n",
      "When input is [25, 17] the target is: 27\n",
      "When input is [25, 17, 27] the target is: 10\n",
      "When input is [25, 17, 27, 10] the target is: 0\n",
      "When input is [25, 17, 27, 10, 0] the target is: 21\n",
      "When input is [25, 17, 27, 10, 0, 21] the target is: 1\n",
      "When input is [25, 17, 27, 10, 0, 21, 1] the target is: 54\n",
      "When input is [25, 17, 27, 10, 0, 21, 1, 54] the target is: 39\n"
     ]
    }
   ],
   "source": [
    "for batch in range(batch_size):\n",
    "    for token in range(block_size):\n",
    "        context = x_batch[batch, :token+1]\n",
    "        target = y_batch[batch,token]\n",
    "        print(f\"When input is {context.tolist()} the target is: {target}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a6209a-ae52-4fda-bb1f-9e95f7b820ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our input to transformer is the batch x\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6f47a-eaf6-431e-af10-bbd28f1380ac",
   "metadata": {},
   "source": [
    "# Create BigramLangaugeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "874f628c-1c18-452b-a9b8-28bf511b1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.3962, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "n_embed = 32\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        \n",
    "        # idx and targets are both (B,T)-> (4,8) tensor of integers\n",
    "        tok_emd = self.token_embedding_table(idx) # (B,T,C)=(4,8,65) -> Batch, Time(time_step = block_size), Channel(n_emd)\n",
    "        logits = self.lm_head(tok_emd)\n",
    "        \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is of the shape (B,T) of the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            print(idx)\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(idx) # No loss is given so (B, T, C)\n",
    "            print(logits)\n",
    "            # get the logits for the last time-step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            print(logits)\n",
    "            # apply softmax to get the probabilities\n",
    "            probs = F.softmax(logits, dim = -1) # (B, C) \n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # (B, 1)\n",
    "            # append sampled index to the running requence\n",
    "            idx = torch.cat((idx,idx_next), dim = 1) # (B, T+1)\n",
    "        return idx\n",
    "            \n",
    "        \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(x_batch, y_batch)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a98412ea-2b62-4a53-b917-e2378d063cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "tensor([[[ 0.2118,  0.0476, -0.5092, -0.3937, -0.6210,  0.4014,  0.5733,\n",
      "          -0.7211, -0.6085, -0.0318, -0.5597, -0.1979,  0.3287, -0.3452,\n",
      "          -0.5187,  0.0695,  0.1754,  0.2898, -0.2082, -0.1928,  0.4454,\n",
      "          -0.8689, -0.2896, -0.1174,  0.6825,  0.3376,  0.2091,  0.1759,\n",
      "          -0.1579,  0.4743,  1.4392,  0.4325, -1.0104, -0.8738,  0.8913,\n",
      "           0.5467, -0.5816, -0.5743, -0.3191,  0.0827, -0.0257,  0.2025,\n",
      "          -0.7261,  0.0587, -0.3726,  0.4051, -0.9708, -0.4792,  0.4587,\n",
      "           0.1132, -0.0613, -0.3580, -0.2526, -0.2331,  0.7537, -0.1269,\n",
      "           0.1412, -0.7482,  0.0841, -1.0373,  0.6100, -0.8797, -0.8562,\n",
      "           1.0132,  0.3666]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.2118,  0.0476, -0.5092, -0.3937, -0.6210,  0.4014,  0.5733, -0.7211,\n",
      "         -0.6085, -0.0318, -0.5597, -0.1979,  0.3287, -0.3452, -0.5187,  0.0695,\n",
      "          0.1754,  0.2898, -0.2082, -0.1928,  0.4454, -0.8689, -0.2896, -0.1174,\n",
      "          0.6825,  0.3376,  0.2091,  0.1759, -0.1579,  0.4743,  1.4392,  0.4325,\n",
      "         -1.0104, -0.8738,  0.8913,  0.5467, -0.5816, -0.5743, -0.3191,  0.0827,\n",
      "         -0.0257,  0.2025, -0.7261,  0.0587, -0.3726,  0.4051, -0.9708, -0.4792,\n",
      "          0.4587,  0.1132, -0.0613, -0.3580, -0.2526, -0.2331,  0.7537, -0.1269,\n",
      "          0.1412, -0.7482,  0.0841, -1.0373,  0.6100, -0.8797, -0.8562,  1.0132,\n",
      "          0.3666]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0, 51]])\n",
      "tensor([[[ 2.1179e-01,  4.7581e-02, -5.0923e-01, -3.9370e-01, -6.2097e-01,\n",
      "           4.0144e-01,  5.7332e-01, -7.2106e-01, -6.0848e-01, -3.1791e-02,\n",
      "          -5.5973e-01, -1.9787e-01,  3.2869e-01, -3.4516e-01, -5.1872e-01,\n",
      "           6.9519e-02,  1.7538e-01,  2.8975e-01, -2.0816e-01, -1.9283e-01,\n",
      "           4.4544e-01, -8.6890e-01, -2.8957e-01, -1.1738e-01,  6.8248e-01,\n",
      "           3.3763e-01,  2.0905e-01,  1.7587e-01, -1.5792e-01,  4.7425e-01,\n",
      "           1.4392e+00,  4.3254e-01, -1.0104e+00, -8.7384e-01,  8.9130e-01,\n",
      "           5.4666e-01, -5.8160e-01, -5.7431e-01, -3.1914e-01,  8.2683e-02,\n",
      "          -2.5693e-02,  2.0253e-01, -7.2610e-01,  5.8668e-02, -3.7263e-01,\n",
      "           4.0510e-01, -9.7078e-01, -4.7916e-01,  4.5871e-01,  1.1320e-01,\n",
      "          -6.1275e-02, -3.5798e-01, -2.5259e-01, -2.3314e-01,  7.5369e-01,\n",
      "          -1.2690e-01,  1.4116e-01, -7.4823e-01,  8.4113e-02, -1.0373e+00,\n",
      "           6.1001e-01, -8.7969e-01, -8.5625e-01,  1.0132e+00,  3.6660e-01],\n",
      "         [-4.8269e-01, -7.5781e-01,  8.6533e-01, -8.0380e-01, -6.7948e-01,\n",
      "           8.0581e-01, -7.4627e-01,  7.1088e-01, -8.3418e-01,  3.2341e-01,\n",
      "           5.9923e-01, -1.9863e-01, -2.1087e-01,  4.2797e-01, -6.9619e-01,\n",
      "           1.6591e-01,  3.2987e-01, -2.2084e-01, -1.2655e-01,  1.4363e-01,\n",
      "           2.2841e-01,  2.5291e-01, -7.8770e-01, -3.8618e-01, -2.3786e-01,\n",
      "          -2.4185e-01, -2.2550e-02, -1.1221e-01, -2.5565e-01, -7.8933e-01,\n",
      "           8.4234e-01, -1.7312e-01,  1.3636e-03,  8.8206e-01, -3.0617e-01,\n",
      "           2.9771e-01,  2.6327e-01,  1.0532e-01,  1.0846e-01,  7.3204e-01,\n",
      "           6.8632e-02,  4.0812e-01, -1.0294e-01, -6.2234e-01,  8.3555e-01,\n",
      "          -6.0289e-01,  3.1641e-02,  1.2158e+00,  1.3530e+00, -8.5036e-02,\n",
      "           6.7681e-01,  2.7980e-01, -7.4015e-01, -2.5917e-01, -2.7706e-01,\n",
      "           7.0561e-01,  1.0600e+00,  6.5963e-02,  3.4058e-01,  4.0283e-01,\n",
      "          -5.7194e-01,  6.2790e-01, -5.1630e-01,  5.6038e-01,  3.3327e-01]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[-0.4827, -0.7578,  0.8653, -0.8038, -0.6795,  0.8058, -0.7463,  0.7109,\n",
      "         -0.8342,  0.3234,  0.5992, -0.1986, -0.2109,  0.4280, -0.6962,  0.1659,\n",
      "          0.3299, -0.2208, -0.1266,  0.1436,  0.2284,  0.2529, -0.7877, -0.3862,\n",
      "         -0.2379, -0.2419, -0.0225, -0.1122, -0.2557, -0.7893,  0.8423, -0.1731,\n",
      "          0.0014,  0.8821, -0.3062,  0.2977,  0.2633,  0.1053,  0.1085,  0.7320,\n",
      "          0.0686,  0.4081, -0.1029, -0.6223,  0.8356, -0.6029,  0.0316,  1.2158,\n",
      "          1.3530, -0.0850,  0.6768,  0.2798, -0.7402, -0.2592, -0.2771,  0.7056,\n",
      "          1.0600,  0.0660,  0.3406,  0.4028, -0.5719,  0.6279, -0.5163,  0.5604,\n",
      "          0.3333]], grad_fn=<SliceBackward0>)\n",
      "\n",
      "mW\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 2)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e240cba0-60c0-4891-bf4d-0fd568a9ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2912, 0.8345, 0.7804, 0.8163, 0.2011, 0.3874, 0.3474, 0.2768,\n",
       "          0.3326, 0.3273, 0.0301, 0.4307, 0.7330, 0.1079, 0.0866, 0.8334,\n",
       "          0.8106, 0.8129, 0.5180, 0.3563, 0.1854, 0.9787, 0.6092, 0.5012,\n",
       "          0.5733, 0.4173, 0.0410, 0.1195, 0.0350, 0.7011, 0.9785, 0.2568,\n",
       "          0.6487, 0.9395, 0.4513, 0.5866, 0.6550, 0.5231, 0.8521, 0.1456,\n",
       "          0.1049, 0.0923, 0.9964, 0.3903, 0.1434, 0.3980, 0.2942, 0.6221,\n",
       "          0.4980, 0.1393, 0.3687, 0.2781, 0.5935, 0.4255, 0.4158, 0.1149,\n",
       "          0.9387, 0.3141, 0.9859, 0.2955, 0.4695, 0.3617, 0.8061, 0.4760,\n",
       "          0.4524]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1,1,65))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3030111b-6418-434e-bdd1-3a70a8f3f6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2912, 0.8345, 0.7804, 0.8163, 0.2011, 0.3874, 0.3474, 0.2768, 0.3326,\n",
       "         0.3273, 0.0301, 0.4307, 0.7330, 0.1079, 0.0866, 0.8334, 0.8106, 0.8129,\n",
       "         0.5180, 0.3563, 0.1854, 0.9787, 0.6092, 0.5012, 0.5733, 0.4173, 0.0410,\n",
       "         0.1195, 0.0350, 0.7011, 0.9785, 0.2568, 0.6487, 0.9395, 0.4513, 0.5866,\n",
       "         0.6550, 0.5231, 0.8521, 0.1456, 0.1049, 0.0923, 0.9964, 0.3903, 0.1434,\n",
       "         0.3980, 0.2942, 0.6221, 0.4980, 0.1393, 0.3687, 0.2781, 0.5935, 0.4255,\n",
       "         0.4158, 0.1149, 0.9387, 0.3141, 0.9859, 0.2955, 0.4695, 0.3617, 0.8061,\n",
       "         0.4760, 0.4524]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99bfb65e-403c-4307-942b-63030c3944f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete a optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e56867c6-9627-421e-ab5c-c4182aa40387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5413219928741455\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb,yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loos\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cddfea-f536-4c4d-9d59-30c7a434c745",
   "metadata": {},
   "source": [
    "# Self Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4111fd8f-6673-479c-bcba-486d60e1adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single head perform self-atention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) ---> (B,T,T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "v = value(x)\n",
    "# out = we @ x\n",
    "out = wei @ v # (B,T,T) * (B,T,C)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81149974-cfcb-41c9-a549-02f582577448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "979671b2-e6bc-44dc-ba33-85e5c9deb101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]), torch.Size([4, 8, 32]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0407f20-3417-4624-b2b5-9751394ad9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d954d9bf-9110-4aed-881a-1e8dea00e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file data/input.txt already exists.\n",
      "step 0: train loss 4.6409, val loss 4.6513\n",
      "step 300: train loss 2.8174, val loss 2.8204\n",
      "step 600: train loss 2.5418, val loss 2.5578\n",
      "step 900: train loss 2.4980, val loss 2.5189\n",
      "step 1200: train loss 2.4812, val loss 2.5142\n",
      "step 1500: train loss 2.4671, val loss 2.4984\n",
      "step 1800: train loss 2.4654, val loss 2.4879\n",
      "step 2100: train loss 2.4651, val loss 2.4918\n",
      "step 2400: train loss 2.4727, val loss 2.4911\n",
      "step 2700: train loss 2.4630, val loss 2.4855\n",
      "\n",
      "AMISpequt f keithunghanturt\n",
      "The orerrofe find ans I andoovyonon-hu he nd youlliler pt icis ig y onee, tie maisewal'steel datarmyo CKE:\n",
      "\n",
      "The e I mong fat.\n",
      "KEEE: f se;JUSA:\n",
      "S:\n",
      "CESatrrondithe gnth araly athe be's o s, BEit gheeer who.\n",
      "\n",
      "We y pe n.\n",
      "THE:\n",
      "QUCA:\n",
      "CK, mf ve shorsld;\n",
      "\n",
      "IOMu y tu,\n",
      "\n",
      "Thincawadu th ce! m; VOPOMII ferir' te e ous,\n",
      "Dell,\n",
      "Phapy IGads,\n",
      "INE f s wittomy tomyord hilid byothitwathoonowf I aninsiloo t t, VIO:\n",
      "Y t mantoreay.\n",
      "Tomsoure daistoweerwesomoo'Foupousinive flactous qun, g I and h\n"
     ]
    }
   ],
   "source": [
    "%run bigram_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75c241b5-11a9-4adf-901c-290e2cc974be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory data/input.txt already exists.\n"
     ]
    }
   ],
   "source": [
    "%run test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23dedcd7-eb90-4ec0-b4d2-301cfca5948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 d\n",
      "2 f\n",
      "3 g\n",
      "4 s\n"
     ]
    }
   ],
   "source": [
    "a = set(\"asfasgasdgs\")\n",
    "for index, num in enumerate(a):\n",
    "    print(index, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e1869-20ba-4f32-a833-24320083c0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
